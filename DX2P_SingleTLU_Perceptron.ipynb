{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DX2P_SingleTLU_Perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9iaISB0KlbO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#**What is a perceptron?**\n",
        "\n",
        "The perceptron is one of the earliest simple feed forward neural networks used for binary classification of data. Specifically, a one neuron system is a single perceptron. One layer of these is called a single layer perceptron. It is an example of supervised learning. Despite its simplicity, it yields a powerful model for accurate classification.\n",
        "\n",
        "**The network and learning algorithm:**\n",
        "\n",
        "The perceptron network begins with input neurons which is a vector of the input features. Each feature is assigned a weight as it feeds into a neuron called a threshold logic unit. In addition, there is a biasing input vector which just has the number 1 as its elements, along with a corresponding weight.These are fed as a linear combination or a vector product of the input vectors and weight vectors into a single layer of neurons. This linear combination mathematically represents a linear decision boundary in the multi-dimensional space where every input feature forms one axis. The aim is to find the linear decision boundary by finding the optimal weights and bias such that it separates the instances of the two classes. \n",
        "\n",
        "The neurons then run a non-linear activation function (mathematical operation) on the weighted sums to yield values typically between 0 and 1 or between -1 and 1. Common functions to achieve these intervals are the binary sigmoidal function and the bipolar sigmoidal function respectively. The output of this function is our predicted output. The desired outputs are 0,1 or -1,1 depending on the problem which is basically deciding whether an input instance belongs to class 0 (or class -1) or class 1. The way the model learns is by being penalized for the errors it makes in prediction as it runs or is trained for every instance.\n",
        "\n",
        "The error in prediction is computed in terms of the cost function. The aim is to minimize the cost function. We run an iterative code through the instances of the input to run the partial differentiation of the cost function with respect to the weights. We update these weights incrementally in the direction opposite to the gradient descent, measure the cost function again and repeat the process. The algorithm could be that of an online or offline learning model. The whole sequence is run either for large enough iterations to expect a low error, or till a certain desired minimum value of cost function, as set by us, is reached. Finally, for each instance, the output will be one of two classes. This is how single-layer perceptrons work.\n",
        "\n",
        "**Pros and Cons:**\n",
        "\n",
        "Perceptrons are fairly simple models to understand and implement, and are good for linearly separable data (e.g. classifying flowers as Setosa or Versicolor using the iris dataset). This very point is a limitation in the broader context as in the real world though, data may not be typically not linearly separable. For example, a XOR problem cannot be solved by a single layer of perceptrons. The need to classify non-linearly separable data is what then gave rise to multi-layer perceptrons or other models such as support vector machines, kernel functions, etc. \n",
        "\n",
        "Despite the scale of application, it is important to know what perceptrons are and how they function as they served as the building blocks of neural networks, and still continue to showcase the power of simplicity. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0eIaqT05tYW",
        "colab_type": "text"
      },
      "source": [
        "# **Solving the NAND Gate : Single TLU Perceptron from Scratch**\n",
        "\n",
        "Task: To predict the outcome of the NAND gate\n",
        "\n",
        "**What is a NAND gate?**\n",
        "\n",
        "It is a logical gate that computes the outcome based on two binary inputs of 1 (True) and 0(False). \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqI_NRhPGU5f",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Input 1 | Input 2 | Output\n",
        ":---|:---:|---:\n",
        "True|True|False\n",
        "False|True|True\n",
        "True|False|True\n",
        "False|False|True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Egvm0r6Hpoc",
        "colab_type": "text"
      },
      "source": [
        "Input 1 | Input 2 | Output\n",
        ":---|:---:|---:\n",
        "1|1|0\n",
        "0|1|1\n",
        "1|0|1\n",
        "0|0|1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yde9-2RIGXug",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "In our code, we take these data points. We have four 2-featured instances as our input. We code a single layer perceptron from scratch that predicts the outcome correctly. \n",
        "\n",
        "**What does coding a neural network from scratch imply?**\n",
        "\n",
        "We do not use inbuilt libraries for machine/ deep learning such as those in scikit-learn, keras or tensor flow.  We use only numpy, pandas, and write functions to make the model, train, fit, predict and evaluate it. \n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avbYReabDIFO",
        "colab_type": "text"
      },
      "source": [
        "## STEP 1. Import the necessary libraries/ functions and get the data ready"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOF3RGEoWI9b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qext1qt8Nrf",
        "colab_type": "code",
        "outputId": "f494cae7-09c9-4b51-9a13-621575c19c2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#We are creating the NAND table data here\n",
        "data=pd.DataFrame([[0,0,1],[0,1,1],[1,0,1],[1,1,0]],columns=[\"x1\",\"x2\",\"y\"])\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2  y\n",
              "0   0   0  1\n",
              "1   0   1  1\n",
              "2   1   0  1\n",
              "3   1   1  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY3Od0WN9Fxt",
        "colab_type": "code",
        "outputId": "81c9c9a8-a538-407f-eb01-91e5c620964a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#Creating a data frame only with the input values\n",
        "X=data.iloc[:,0:2]\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   x1  x2\n",
              "0   0   0\n",
              "1   0   1\n",
              "2   1   0\n",
              "3   1   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnfeI8rJ8vCu",
        "colab_type": "code",
        "outputId": "a5226abd-8779-42eb-f915-0cfee9cc2d60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#Creating a data frame only with the output values\n",
        "Y = data[\"y\"]\n",
        "Y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    0\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvmyX80WDWFA",
        "colab_type": "code",
        "outputId": "00b0e0c9-584f-4772-d8d0-801ee6ea5753",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "#In our code, we want to integrate the bias terms into the matrix of input value. \n",
        "#This way, our weighted sum becomes the following: WX instead of WX + b, where b #is a separate, bias vector\n",
        "\n",
        "#Inserting a new column into the pandas dataframe where every elemnt is 1, in the first position\n",
        "X.insert(0,\"bias\", np.ones(X.shape[0]), True)\n",
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bias</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bias  x1  x2\n",
              "0   1.0   0   0\n",
              "1   1.0   0   1\n",
              "2   1.0   1   0\n",
              "3   1.0   1   1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfZLxRaDDWoZ",
        "colab_type": "text"
      },
      "source": [
        "## STEP 2: Write the feed forward function that predicts the outcome using the weights and inputs\n",
        "\n",
        "This function is used to predict the activated output at a layer, and is called for each instance of X (corresponds to each row in the X matrix). It thus takes in a row of the input features (= the vector of feature values for that instance) and the updated weights as its parameter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiScivihN_9t",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGzSWlDxWifW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def predict(instance ,weights ):\n",
        "  #Initializing a variable to hold the value of the weighted sum (of input features and the corresponding weights) \n",
        "  weighted_sum=0 \n",
        "\n",
        "  #calculating the weighted sum of the instance features and the corresponding weights as a dot product\n",
        "  weighted_sum=np.dot(instance,weights)\n",
        "\n",
        "#Another way of doing this (using loops instead of numpy)\n",
        "# for i in range(len(instance)):\n",
        "  #   weighted_sum += weights[i] * instance[i]\n",
        "\n",
        "  #Step activation function - maps non-negative inputs (function inputs, the weighted sum here) to 1 and negative inputs to 0. \n",
        "  #Using an if statement for the step activation function\n",
        "  if weighted_sum >= 0:\n",
        "    activation=1.0\n",
        "  else:\n",
        "    activation=0.0\n",
        "  return activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9r90cJeDlDR",
        "colab_type": "text"
      },
      "source": [
        "## STEP 3: Define the function that trains the weight using backpropogation using gradient descent. \n",
        "\n",
        "Here, we use stochastic gradient descent which means we we go through all the instances one by one and update the weights after each time an instance is passed in the forward direction. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdyxTUNCOT0z",
        "colab_type": "text"
      },
      "source": [
        "**Weight update:**\n",
        "\n",
        "updated weight = old weight - update in weight\n",
        "\n",
        "> where:\n",
        "\n",
        "> update in the weight = learning rate * (desired output - actual (or predicted) output) * input\n",
        "  \n",
        "Each of the weights (corresponding to each input feature) gets updated"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqxRPYqri1LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#learning_rate and epochs are hyperparameters here, that is, we specify their values (we try different values to see which one helps our model train / converge the best)\n",
        "def train_weights(x,y, learning_rate, epochs):\n",
        "  #initializing a weight vector (array of 1 dimension here as there is only one neuron) whose length is equal to the number of input features\n",
        "  weights = np.ones(x.shape[1]) #The no. of input features in x is given by the number of columns x has. It can be obtained from the shape. Run x.shape and see what you get.\n",
        "  #We look at the error in predictions for all instances, and do that for each epoch\n",
        "  for epoch in range(epochs): #for every epoch\n",
        "    total_error = 0.0 #storing the total error for that epoch\n",
        "    for index in range(len(x)): #for each instance of x (instance being represented by a row) \n",
        "      prediction = predict(x.iloc[index], weights)\n",
        "      error = y.iloc[index]-prediction \n",
        "      total_error += error **2 #sum of squared error\n",
        "      for j in range(x.shape[1]): \n",
        "        #Updating each of the weights (that is, the weight value corresponding to each of the input features) \n",
        "        weights[j] = weights[j] + learning_rate *error * x.iloc[index,j]\n",
        "    mean_sq_error = total_error/len(x)\n",
        "    #printing the epoch number, the learning rate and mean of the total error for that epoch\n",
        "    print(f'Epochs = {epoch}, learning rate = {learning_rate}, mean squared error(MSE) = {mean_sq_error}')\n",
        "  return weights #these are the final, trained weights after running through all the epochs - used in prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq6vIyE_EDy4",
        "colab_type": "text"
      },
      "source": [
        "## STEP 4: Define the function that serves as the model \n",
        "\n",
        "This function will call the training and predict functions, and computes the final predicted outcome after running through all the epochs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfJHFMbcneGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the function that calls the training function, and computes the final outcome\n",
        "def perceptron(X, Y, learning_rate, epochs):\n",
        "  y_preds = list() #initializing a variable to hold the predicted values (one prediction for each instance) as a list\n",
        "  weights = train_weights(X, Y, learning_rate, epochs)\n",
        "  for i in range(len(X)):\n",
        "    #for each instance/ row of X, getting the prediction and appending it to the list\n",
        "    prediction = predict(X.iloc[i],weights)\n",
        "    y_preds.append(prediction)\n",
        "  return y_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdxwqjbnEuoC",
        "colab_type": "text"
      },
      "source": [
        "## STEP 5: Define a function that evaluates the accuracy score\n",
        "\n",
        "Now that we have predicted the outcome, we need to compute the accuracy of our model. We use a simple accuracy metric in this code, as described below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVFa-voKvOQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(y_desired, y_predicted):\n",
        "  correct = 0\n",
        "  \n",
        "  #computing accuracy as the percent correctness of the predictions among the instances\n",
        "  #Defined here as the %percent of correct predictions out of all the instances the model predicted for\n",
        "  for i in range(len(y_desired)):\n",
        "    if y_desired[i] == predicted[i]:\n",
        "      correct += 1\n",
        "  accuracy_score=correct*100.0/len(y_desired)\n",
        "  return accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p7k612MpTDI",
        "colab_type": "text"
      },
      "source": [
        "### STEP 6: Tune the hyperparameters, run the model, obtain the accuracy score. Repeat for different values of the hyperparameters and see what values give you the best performing model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBmoEK8T0huB",
        "colab_type": "code",
        "outputId": "cdede80f-8a98-4a06-c268-589b581284ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "source": [
        "#Iitializing the hyperparameters\n",
        "learning_rate = 0.5\n",
        "epochs = 30\n",
        "\n",
        "#calling the model, predicting the outcome and measuring the accuracy of the prediction\n",
        "predicted = perceptron(X, Y, learning_rate, epochs)\n",
        "accuracy = accuracy_score(Y, predicted)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(f\"The accuracy is {accuracy}%.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs = 0, learning rate = 0.5, mean squared error(MSE) = 0.25\n",
            "Epochs = 1, learning rate = 0.5, mean squared error(MSE) = 0.25\n",
            "Epochs = 2, learning rate = 0.5, mean squared error(MSE) = 0.25\n",
            "Epochs = 3, learning rate = 0.5, mean squared error(MSE) = 0.75\n",
            "Epochs = 4, learning rate = 0.5, mean squared error(MSE) = 0.75\n",
            "Epochs = 5, learning rate = 0.5, mean squared error(MSE) = 0.5\n",
            "Epochs = 6, learning rate = 0.5, mean squared error(MSE) = 0.25\n",
            "Epochs = 7, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 8, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 9, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 10, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 11, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 12, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 13, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 14, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 15, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 16, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 17, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 18, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 19, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 20, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 21, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 22, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 23, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 24, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 25, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 26, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 27, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 28, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "Epochs = 29, learning rate = 0.5, mean squared error(MSE) = 0.0\n",
            "\n",
            "\n",
            "The accuracy is 100.0%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqNRFdDBGsN",
        "colab_type": "code",
        "outputId": "c29c7c66-5d81-4f55-9f97-fa8a05f4859a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.xlim(-1,3)\n",
        "plt.xticks(np.arange(0,3,1))\n",
        "plt.yticks(np.arange(0,3,1))\n",
        "plt.ylim(-1,3)\n",
        "plt.grid()\n",
        "plt.scatter(X[data[\"y\"]==1][\"x1\"], X[data[\"y\"]==1][\"x2\"], s=120, c=\"r\", marker=\"^\")\n",
        "plt.scatter(X[data[\"y\"]==0][\"x1\"], X[data[\"y\"]==0][\"x2\"], s=120, c=\"b\", marker=\"o\")\n",
        "\n",
        "#plt.plot(data[data[\"y\"]==1][\"x1\"],data[data[\"y\"]==1][\"x2\"],'o',c=\"b\")\n",
        "#plt.plot(data[data[\"y\"]==0][\"x1\"],data[data[\"y\"]==0][\"x2\"],'^',c=\"r\")\n",
        "plt.title('NAND Gate')\n",
        "plt.xlabel('x1', color='#1C2833',fontsize=16)\n",
        "plt.ylabel('x2', color='#1C2833',fontsize=16)\n",
        "plt.legend(loc='upper left')\n",
        "for i_x, i_y in zip(data[\"x1\"], data[\"x2\"]):\n",
        "    plt.text(i_x+0.1, i_y+0.1, '({}, {})'.format(i_x, i_y),fontsize=22)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAJiCAYAAAASbBxtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBBcAQGP/P9iJCTD6elyRAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgqKWb4W8xRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plt.subplot(321)\n",
        "# plt.scatter(X[data[\"y\"]==1][\"x1\"], X[data[\"y\"]==1][\"x2\"], s=80, c=\"r\", marker=\">\")\n",
        "# for i in range(len(data)):\n",
        "#   x1=data.iloc[i,0]\n",
        "#   x2=data.iloc[i:1]\n",
        "#   plt.text(x1,x2,f\"{x1},{x2}\")\n",
        "#   print(\"check\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q55PwtHOkZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}